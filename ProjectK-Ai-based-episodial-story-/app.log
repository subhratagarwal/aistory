2025-04-21 22:32:13,138 - config - INFO - Initial Model Provider: openai
2025-04-21 22:32:13,139 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-04-21 22:32:13,140 - config - INFO - Initial Big Model: gpt-4-turbo
2025-04-21 22:32:13,140 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-21 22:34:25,481 - config - INFO - Initial Model Provider: openai
2025-04-21 22:34:25,482 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-04-21 22:34:25,482 - config - INFO - Initial Big Model: gpt-4-turbo
2025-04-21 22:34:25,483 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-21 22:45:16,700 - config - INFO - Initial Model Provider: openai
2025-04-21 22:45:16,700 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-04-21 22:45:16,701 - config - INFO - Initial Big Model: gpt-4-turbo
2025-04-21 22:45:16,701 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-21 22:46:37,515 - config - INFO - Initial Model Provider: openai
2025-04-21 22:46:37,516 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-04-21 22:46:37,516 - config - INFO - Initial Big Model: gpt-4-turbo
2025-04-21 22:46:37,516 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-21 23:58:25,254 - config - INFO - Initial Model Provider: openai
2025-04-21 23:58:25,255 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-04-21 23:58:25,255 - config - INFO - Initial Big Model: gpt-4-turbo
2025-04-21 23:58:25,256 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-22 00:00:58,465 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 00:00:58,467 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 00:00:58,467 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 00:01:16,959 - pipeline - INFO - Generating story for idea: a haunted house where a person is alone...
2025-04-22 00:01:17,997 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:18,001 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:18,002 - pipeline - INFO - Created directory for story: stories\Error_Error_code_401_-
2025-04-22 00:01:18,659 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:18,660 - query_handler - ERROR - Error generating response with gpt-4-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:18,664 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_bible.txt
2025-04-22 00:01:19,512 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:19,513 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:19,513 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 00:01:19,514 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:01:20,199 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:20,200 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:20,847 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:20,848 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:20,849 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:01:21,529 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:21,529 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:21,531 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:01:22,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:22,372 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:23,119 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:23,120 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:23,120 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:01:23,882 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:23,884 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:23,886 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:01:23,892 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story.txt
2025-04-22 00:01:23,898 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_summaries.txt
2025-04-22 00:01:23,898 - pipeline - INFO - Story 'Error_Error_code_401_-' generated successfully with 2 episodes
2025-04-22 00:01:35,083 - pipeline - INFO - Generating story for idea: a haunted house where a person is alone...
2025-04-22 00:01:35,952 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:35,953 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:35,954 - pipeline - INFO - Created directory for story: stories\Error_Error_code_401_-
2025-04-22 00:01:36,967 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:36,968 - query_handler - ERROR - Error generating response with gpt-4-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:36,970 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_bible.txt
2025-04-22 00:01:37,889 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:37,890 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:37,890 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 00:01:37,891 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:01:38,746 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:38,746 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:39,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:39,401 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:39,401 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:01:40,154 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:40,155 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:40,157 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:01:40,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:40,825 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:41,435 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:41,436 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:41,437 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:01:42,327 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:01:42,329 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:01:42,330 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:01:42,332 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story.txt
2025-04-22 00:01:42,334 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_summaries.txt
2025-04-22 00:01:42,334 - pipeline - INFO - Story 'Error_Error_code_401_-' generated successfully with 2 episodes
2025-04-22 00:01:59,785 - pipeline - INFO - Generating story for idea: a haunted house where a person is alone...
2025-04-22 00:02:00,536 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:00,537 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:00,537 - pipeline - INFO - Created directory for story: stories\Error_Error_code_401_-
2025-04-22 00:02:01,152 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:01,153 - query_handler - ERROR - Error generating response with gpt-4-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:01,154 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_bible.txt
2025-04-22 00:02:01,778 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:01,779 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:01,779 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 00:02:01,780 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:02:02,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:02,929 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:04,090 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:04,092 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:04,093 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:02:04,889 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:04,891 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:04,894 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:02:05,528 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:05,529 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:06,276 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:06,277 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:06,278 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:02:07,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:07,277 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:07,279 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:02:07,280 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story.txt
2025-04-22 00:02:07,282 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_summaries.txt
2025-04-22 00:02:07,283 - pipeline - INFO - Story 'Error_Error_code_401_-' generated successfully with 2 episodes
2025-04-22 00:02:16,882 - pipeline - INFO - Generating story for idea: a haunted house where a person is alone...
2025-04-22 00:02:18,247 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:18,248 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:18,249 - pipeline - INFO - Created directory for story: stories\Error_Error_code_401_-
2025-04-22 00:02:18,928 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:18,930 - query_handler - ERROR - Error generating response with gpt-4-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:18,931 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_bible.txt
2025-04-22 00:02:19,646 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:19,647 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:19,647 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 00:02:19,650 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:02:21,221 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:21,222 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:21,869 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:21,870 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:21,870 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:02:22,663 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:22,664 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:22,667 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:02:23,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:23,256 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:25,242 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:25,244 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:25,245 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:02:25,990 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:02:25,993 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-*********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:02:25,997 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:02:26,000 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story.txt
2025-04-22 00:02:26,003 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_summaries.txt
2025-04-22 00:02:26,003 - pipeline - INFO - Story 'Error_Error_code_401_-' generated successfully with 2 episodes
2025-04-22 00:05:08,884 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 00:05:08,886 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 00:05:08,887 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 00:05:15,835 - pipeline - INFO - Generating story for idea: a haunted house where a person is alone...
2025-04-22 00:05:16,671 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:05:16,672 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:05:16,673 - pipeline - INFO - Created directory for story: stories\Error_Error_code_401_-
2025-04-22 00:05:17,860 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:05:17,861 - query_handler - ERROR - Error generating response with gpt-4-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:05:17,862 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_bible.txt
2025-04-22 00:05:18,511 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:05:18,512 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:05:18,512 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 00:05:18,514 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:05:19,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:05:19,140 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:05:19,961 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:05:19,962 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:05:19,962 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:05:20,567 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:05:20,568 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:05:20,570 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:05:21,204 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:05:21,205 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:05:21,822 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:05:21,822 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:05:21,823 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:05:23,077 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:05:23,079 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:05:23,081 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:05:23,082 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story.txt
2025-04-22 00:05:23,084 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_summaries.txt
2025-04-22 00:05:23,085 - pipeline - INFO - Story 'Error_Error_code_401_-' generated successfully with 2 episodes
2025-04-22 00:06:53,490 - pipeline - INFO - Generating story for idea: a haunted house where a person is alone...
2025-04-22 00:06:54,359 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:06:54,360 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:06:54,361 - pipeline - INFO - Created directory for story: stories\Error_Error_code_401_-
2025-04-22 00:06:54,950 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:06:54,951 - query_handler - ERROR - Error generating response with gpt-4-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:06:54,953 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_bible.txt
2025-04-22 00:06:56,048 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:06:56,048 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:06:56,049 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 00:06:56,050 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:06:56,689 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:06:56,690 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:06:57,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:06:57,330 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:06:57,330 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:06:57,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:06:57,996 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:06:57,997 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:06:58,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:06:58,578 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:06:59,306 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:06:59,306 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:06:59,307 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:06:59,918 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:06:59,919 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:06:59,920 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:06:59,922 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story.txt
2025-04-22 00:06:59,924 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_summaries.txt
2025-04-22 00:06:59,925 - pipeline - INFO - Story 'Error_Error_code_401_-' generated successfully with 2 episodes
2025-04-22 00:07:27,094 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 00:07:27,095 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 00:07:27,096 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 00:08:21,115 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 00:08:21,115 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 00:08:21,116 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 00:08:48,293 - pipeline - INFO - Generating story for idea: a haunted house where a person is alone...
2025-04-22 00:08:49,085 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:08:49,086 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:08:49,087 - pipeline - INFO - Created directory for story: stories\Error_Error_code_401_-
2025-04-22 00:08:49,750 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:08:49,752 - query_handler - ERROR - Error generating response with gpt-4-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:08:49,757 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_bible.txt
2025-04-22 00:08:50,345 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:08:50,345 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:08:50,346 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 00:08:50,347 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:08:51,037 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:08:51,039 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:08:52,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:08:52,140 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:08:52,141 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:08:53,910 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:08:53,911 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:08:53,913 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:08:54,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:08:54,598 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:08:55,945 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:08:55,946 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:08:55,947 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:08:56,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:08:56,669 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************rMA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:08:56,672 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:08:56,673 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story.txt
2025-04-22 00:08:56,676 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_summaries.txt
2025-04-22 00:08:56,678 - pipeline - INFO - Story 'Error_Error_code_401_-' generated successfully with 2 episodes
2025-04-22 00:12:36,137 - config - INFO - Initial Model Provider: openai
2025-04-22 00:12:36,137 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-04-22 00:12:36,137 - config - INFO - Initial Big Model: gpt-4-turbo
2025-04-22 00:12:36,137 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-22 00:12:45,312 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 00:12:45,313 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 00:12:45,313 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 00:13:24,571 - pipeline - INFO - Generating story for idea: a haunted house where i found a mysterious door...
2025-04-22 00:13:26,166 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:26,167 - openai._base_client - INFO - Retrying request to /chat/completions in 0.420660 seconds
2025-04-22 00:13:26,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:26,875 - openai._base_client - INFO - Retrying request to /chat/completions in 0.959434 seconds
2025-04-22 00:13:28,133 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:28,134 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:13:28,135 - pipeline - INFO - Created directory for story: stories\Error_Error_code_429_-
2025-04-22 00:13:29,303 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-04-22 00:13:29,307 - query_handler - ERROR - Error generating response with gpt-4-turbo: Error code: 404 - {'error': {'message': 'The model `gpt-4-turbo` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2025-04-22 00:13:29,312 - pipeline - INFO - Saved content to stories\Error_Error_code_429_-\story_bible.txt
2025-04-22 00:13:30,398 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:30,398 - openai._base_client - INFO - Retrying request to /chat/completions in 0.410450 seconds
2025-04-22 00:13:31,092 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:31,093 - openai._base_client - INFO - Retrying request to /chat/completions in 0.910941 seconds
2025-04-22 00:13:32,298 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:32,299 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:13:32,300 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 00:13:32,302 - pipeline - INFO - Saved metadata to stories\Error_Error_code_429_-\metadata.json
2025-04-22 00:13:32,903 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:32,904 - openai._base_client - INFO - Retrying request to /chat/completions in 0.450471 seconds
2025-04-22 00:13:33,651 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:33,652 - openai._base_client - INFO - Retrying request to /chat/completions in 0.976835 seconds
2025-04-22 00:13:34,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:34,925 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:13:35,534 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:35,535 - openai._base_client - INFO - Retrying request to /chat/completions in 0.415869 seconds
2025-04-22 00:13:36,250 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:36,251 - openai._base_client - INFO - Retrying request to /chat/completions in 0.962863 seconds
2025-04-22 00:13:37,503 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:37,504 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:13:37,505 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:13:38,150 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:38,151 - openai._base_client - INFO - Retrying request to /chat/completions in 0.380513 seconds
2025-04-22 00:13:38,826 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:38,827 - openai._base_client - INFO - Retrying request to /chat/completions in 0.817912 seconds
2025-04-22 00:13:39,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:39,937 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:13:39,938 - pipeline - INFO - Saved metadata to stories\Error_Error_code_429_-\metadata.json
2025-04-22 00:13:40,521 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:40,522 - openai._base_client - INFO - Retrying request to /chat/completions in 0.401610 seconds
2025-04-22 00:13:41,211 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:41,212 - openai._base_client - INFO - Retrying request to /chat/completions in 0.979551 seconds
2025-04-22 00:13:42,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:42,479 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:13:43,089 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:43,090 - openai._base_client - INFO - Retrying request to /chat/completions in 0.430706 seconds
2025-04-22 00:13:43,815 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:43,816 - openai._base_client - INFO - Retrying request to /chat/completions in 0.824598 seconds
2025-04-22 00:13:44,931 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:44,932 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:13:44,932 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:13:45,545 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:45,546 - openai._base_client - INFO - Retrying request to /chat/completions in 0.455005 seconds
2025-04-22 00:13:46,278 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:46,279 - openai._base_client - INFO - Retrying request to /chat/completions in 0.962687 seconds
2025-04-22 00:13:47,523 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:13:47,525 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:13:47,527 - pipeline - INFO - Saved metadata to stories\Error_Error_code_429_-\metadata.json
2025-04-22 00:13:47,530 - pipeline - INFO - Saved content to stories\Error_Error_code_429_-\story.txt
2025-04-22 00:13:47,532 - pipeline - INFO - Saved content to stories\Error_Error_code_429_-\story_summaries.txt
2025-04-22 00:13:47,533 - pipeline - INFO - Story 'Error_Error_code_429_-' generated successfully with 2 episodes
2025-04-22 00:14:06,970 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 00:14:06,970 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 00:14:06,970 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 00:14:25,482 - pipeline - INFO - Generating story for idea: a haunted house where i found a mysterious door...
2025-04-22 00:14:26,194 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:14:26,195 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************BIA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:14:26,196 - pipeline - INFO - Created directory for story: stories\Error_Error_code_401_-
2025-04-22 00:14:27,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:14:27,385 - query_handler - ERROR - Error generating response with gpt-4-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************BIA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:14:27,389 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_bible.txt
2025-04-22 00:14:28,152 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:14:28,154 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************BIA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:14:28,155 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 00:14:28,157 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:14:28,827 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:14:28,828 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************BIA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:14:29,476 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:14:29,477 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************BIA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:14:29,478 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:14:30,320 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:14:30,321 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************BIA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:14:30,322 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:14:30,985 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:14:30,986 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************BIA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:14:31,806 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:14:31,808 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************BIA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:14:31,809 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:14:32,444 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 00:14:32,445 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: "sk-proj**********************************************************************************************************************************************************BIA". You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 00:14:32,447 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 00:14:32,450 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story.txt
2025-04-22 00:14:32,453 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_summaries.txt
2025-04-22 00:14:32,454 - pipeline - INFO - Story 'Error_Error_code_401_-' generated successfully with 2 episodes
2025-04-22 00:31:24,734 - config - INFO - Initial Model Provider: openai
2025-04-22 00:31:24,735 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-04-22 00:31:24,735 - config - INFO - Initial Big Model: gpt-4-turbo
2025-04-22 00:31:24,736 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-22 00:33:31,265 - config - INFO - Initial Model Provider: openai
2025-04-22 00:33:31,275 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-04-22 00:33:31,276 - config - INFO - Initial Big Model: gpt-4-turbo
2025-04-22 00:33:31,276 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-22 00:33:31,372 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 00:33:31,373 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 00:33:31,373 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 00:33:59,255 - pipeline - INFO - Generating story for idea: a haunted house where i met with a mysterious pers...
2025-04-22 00:34:00,799 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:00,803 - openai._base_client - INFO - Retrying request to /chat/completions in 0.438349 seconds
2025-04-22 00:34:01,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:01,619 - openai._base_client - INFO - Retrying request to /chat/completions in 0.838291 seconds
2025-04-22 00:34:02,845 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:02,850 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:34:02,853 - pipeline - INFO - Created directory for story: stories\Error_Error_code_429_-
2025-04-22 00:34:04,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-04-22 00:34:04,037 - query_handler - ERROR - Error generating response with gpt-4-turbo: Error code: 404 - {'error': {'message': 'The model `gpt-4-turbo` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2025-04-22 00:34:04,047 - pipeline - INFO - Saved content to stories\Error_Error_code_429_-\story_bible.txt
2025-04-22 00:34:05,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:05,315 - openai._base_client - INFO - Retrying request to /chat/completions in 0.438541 seconds
2025-04-22 00:34:06,097 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:06,100 - openai._base_client - INFO - Retrying request to /chat/completions in 0.894630 seconds
2025-04-22 00:34:07,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:07,352 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:34:07,353 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 00:34:07,365 - pipeline - INFO - Saved metadata to stories\Error_Error_code_429_-\metadata.json
2025-04-22 00:34:09,340 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:09,343 - openai._base_client - INFO - Retrying request to /chat/completions in 0.401303 seconds
2025-04-22 00:34:10,122 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:10,126 - openai._base_client - INFO - Retrying request to /chat/completions in 0.906567 seconds
2025-04-22 00:34:11,347 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:11,351 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:34:12,614 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:12,616 - openai._base_client - INFO - Retrying request to /chat/completions in 0.443724 seconds
2025-04-22 00:34:13,392 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:13,396 - openai._base_client - INFO - Retrying request to /chat/completions in 0.967888 seconds
2025-04-22 00:34:14,730 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:14,734 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:34:14,736 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:34:15,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:15,932 - openai._base_client - INFO - Retrying request to /chat/completions in 0.385705 seconds
2025-04-22 00:34:16,667 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:16,670 - openai._base_client - INFO - Retrying request to /chat/completions in 0.800596 seconds
2025-04-22 00:34:17,875 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:17,880 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:34:17,889 - pipeline - INFO - Saved metadata to stories\Error_Error_code_429_-\metadata.json
2025-04-22 00:34:19,742 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:19,744 - openai._base_client - INFO - Retrying request to /chat/completions in 0.436853 seconds
2025-04-22 00:34:20,519 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:20,522 - openai._base_client - INFO - Retrying request to /chat/completions in 0.759997 seconds
2025-04-22 00:34:21,614 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:21,617 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:34:22,767 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:22,769 - openai._base_client - INFO - Retrying request to /chat/completions in 0.434244 seconds
2025-04-22 00:34:23,584 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:23,585 - openai._base_client - INFO - Retrying request to /chat/completions in 0.938052 seconds
2025-04-22 00:34:24,858 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:24,861 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:34:24,862 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:34:26,190 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:26,192 - openai._base_client - INFO - Retrying request to /chat/completions in 0.485130 seconds
2025-04-22 00:34:27,090 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:27,093 - openai._base_client - INFO - Retrying request to /chat/completions in 0.831508 seconds
2025-04-22 00:34:28,218 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:34:28,220 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:34:28,222 - pipeline - INFO - Saved metadata to stories\Error_Error_code_429_-\metadata.json
2025-04-22 00:34:28,228 - pipeline - INFO - Saved content to stories\Error_Error_code_429_-\story.txt
2025-04-22 00:34:28,231 - pipeline - INFO - Saved content to stories\Error_Error_code_429_-\story_summaries.txt
2025-04-22 00:34:28,232 - pipeline - INFO - Story 'Error_Error_code_429_-' generated successfully with 2 episodes
2025-04-22 00:40:43,922 - config - INFO - Initial Model Provider: openai
2025-04-22 00:40:43,923 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-04-22 00:40:43,923 - config - INFO - Initial Big Model: gpt-4-turbo
2025-04-22 00:40:43,924 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-22 00:42:05,897 - config - INFO - Initial Model Provider: openai
2025-04-22 00:42:05,897 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-04-22 00:42:05,898 - config - INFO - Initial Big Model: gpt-4-turbo
2025-04-22 00:42:05,898 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-22 00:42:24,028 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 00:42:24,028 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 00:42:24,028 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 00:42:41,145 - pipeline - INFO - Generating story for idea: a haunted house where i met a mysterious man...
2025-04-22 00:42:42,882 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:42,884 - openai._base_client - INFO - Retrying request to /chat/completions in 0.425231 seconds
2025-04-22 00:42:43,610 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:43,613 - openai._base_client - INFO - Retrying request to /chat/completions in 0.978257 seconds
2025-04-22 00:42:45,285 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:45,289 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:42:45,293 - pipeline - INFO - Created directory for story: stories\Error_Error_code_429_-
2025-04-22 00:42:46,565 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-04-22 00:42:46,569 - query_handler - ERROR - Error generating response with gpt-4-turbo: Error code: 404 - {'error': {'message': 'The model `gpt-4-turbo` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}
2025-04-22 00:42:46,577 - pipeline - INFO - Saved content to stories\Error_Error_code_429_-\story_bible.txt
2025-04-22 00:42:48,365 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:48,368 - openai._base_client - INFO - Retrying request to /chat/completions in 0.499075 seconds
2025-04-22 00:42:49,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:49,189 - openai._base_client - INFO - Retrying request to /chat/completions in 0.796195 seconds
2025-04-22 00:42:50,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:50,335 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:42:50,337 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 00:42:50,348 - pipeline - INFO - Saved metadata to stories\Error_Error_code_429_-\metadata.json
2025-04-22 00:42:51,515 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:51,517 - openai._base_client - INFO - Retrying request to /chat/completions in 0.493453 seconds
2025-04-22 00:42:52,342 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:52,346 - openai._base_client - INFO - Retrying request to /chat/completions in 0.835785 seconds
2025-04-22 00:42:53,497 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:53,502 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:42:55,270 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:55,273 - openai._base_client - INFO - Retrying request to /chat/completions in 0.460593 seconds
2025-04-22 00:42:56,141 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:56,145 - openai._base_client - INFO - Retrying request to /chat/completions in 0.761293 seconds
2025-04-22 00:42:57,225 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:57,230 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:42:57,231 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:42:58,498 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:58,501 - openai._base_client - INFO - Retrying request to /chat/completions in 0.486090 seconds
2025-04-22 00:42:59,297 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:42:59,299 - openai._base_client - INFO - Retrying request to /chat/completions in 0.937951 seconds
2025-04-22 00:43:00,649 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:43:00,653 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:43:00,662 - pipeline - INFO - Saved metadata to stories\Error_Error_code_429_-\metadata.json
2025-04-22 00:43:02,394 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:43:02,397 - openai._base_client - INFO - Retrying request to /chat/completions in 0.456801 seconds
2025-04-22 00:43:03,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:43:03,164 - openai._base_client - INFO - Retrying request to /chat/completions in 0.959374 seconds
2025-04-22 00:43:04,438 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:43:04,444 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:43:06,329 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:43:06,331 - openai._base_client - INFO - Retrying request to /chat/completions in 0.476358 seconds
2025-04-22 00:43:07,168 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:43:07,170 - openai._base_client - INFO - Retrying request to /chat/completions in 0.979756 seconds
2025-04-22 00:43:08,485 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:43:08,489 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:43:08,490 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 00:43:09,734 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:43:09,737 - openai._base_client - INFO - Retrying request to /chat/completions in 0.442433 seconds
2025-04-22 00:43:10,495 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:43:10,498 - openai._base_client - INFO - Retrying request to /chat/completions in 0.908913 seconds
2025-04-22 00:43:11,710 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 00:43:11,714 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 00:43:11,719 - pipeline - INFO - Saved metadata to stories\Error_Error_code_429_-\metadata.json
2025-04-22 00:43:11,727 - pipeline - INFO - Saved content to stories\Error_Error_code_429_-\story.txt
2025-04-22 00:43:11,735 - pipeline - INFO - Saved content to stories\Error_Error_code_429_-\story_summaries.txt
2025-04-22 00:43:11,736 - pipeline - INFO - Story 'Error_Error_code_429_-' generated successfully with 2 episodes
2025-04-22 02:08:24,321 - config - INFO - Initial Model Provider: openai
2025-04-22 02:08:24,322 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-04-22 02:08:24,322 - config - INFO - Initial Big Model: gpt-4-turbo
2025-04-22 02:08:24,322 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-22 02:08:39,198 - config - INFO - Configuration reloaded, using provider: ollama
2025-04-22 02:08:39,198 - config - INFO - Small Model: mistral
2025-04-22 02:08:39,198 - config - INFO - Big Model: llama3
2025-04-22 02:09:22,489 - pipeline - INFO - Generating story for idea: in a haunted house i met with a mystrious person...
2025-04-22 02:09:25,026 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 02:10:56,904 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-22 02:17:57,280 - pipeline - INFO - Created directory for story: stories\Title_Echoes_from_the_Ghostly
2025-04-22 02:18:00,328 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 02:24:30,449 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-22 02:29:02,981 - pipeline - WARNING - File not found: stories\Title_Echoes_from_the_Ghostly\story.txt
2025-04-22 02:48:19,572 - config - INFO - Initial Model Provider: ollama
2025-04-22 02:48:19,573 - config - INFO - Initial Small Model: mistral
2025-04-22 02:48:19,573 - config - INFO - Initial Big Model: llama3
2025-04-22 02:48:19,573 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-22 02:48:39,171 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 02:48:39,171 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 02:48:39,172 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 02:48:49,863 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 02:48:49,864 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 02:48:49,864 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 02:49:15,529 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 02:49:15,530 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 02:49:15,530 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 02:49:52,881 - pipeline - INFO - Generating story for idea: i met a mysterious man in a haunted house...
2025-04-22 02:49:53,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 02:49:53,671 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************IIwA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 02:49:53,673 - pipeline - INFO - Created directory for story: stories\Error_Error_code_401_-
2025-04-22 02:49:54,302 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 02:49:54,303 - query_handler - ERROR - Error generating response with gpt-4-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************IIwA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 02:49:54,304 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_bible.txt
2025-04-22 02:49:54,883 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 02:49:54,884 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************IIwA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 02:49:54,884 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 02:49:54,887 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 02:49:56,043 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 02:49:56,045 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************IIwA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 02:49:56,639 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 02:49:56,639 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************IIwA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 02:49:56,640 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 02:49:57,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 02:49:57,246 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************IIwA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 02:49:57,248 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 02:49:57,840 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 02:49:57,841 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************IIwA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 02:49:58,436 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 02:49:58,437 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************IIwA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 02:49:58,437 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-04-22 02:49:59,070 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-04-22 02:49:59,071 - query_handler - ERROR - Error generating response with gpt-3.5-turbo: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************IIwA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
2025-04-22 02:49:59,073 - pipeline - INFO - Saved metadata to stories\Error_Error_code_401_-\metadata.json
2025-04-22 02:49:59,078 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story.txt
2025-04-22 02:49:59,081 - pipeline - INFO - Saved content to stories\Error_Error_code_401_-\story_summaries.txt
2025-04-22 02:49:59,082 - pipeline - INFO - Story 'Error_Error_code_401_-' generated successfully with 2 episodes
2025-04-22 02:50:48,959 - config - INFO - Configuration reloaded, using provider: ollama
2025-04-22 02:50:48,960 - config - INFO - Small Model: mistral
2025-04-22 02:50:48,960 - config - INFO - Big Model: llama3
2025-04-22 03:02:51,398 - config - INFO - Initial Model Provider: ollama
2025-04-22 03:02:51,398 - config - INFO - Initial Small Model: mistral
2025-04-22 03:02:51,399 - config - INFO - Initial Big Model: llama3
2025-04-22 03:02:51,399 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-22 03:03:46,229 - pipeline - INFO - Generating story for idea: a beautiful season ...
2025-04-22 03:03:47,267 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 03:05:33,311 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-22 03:09:14,370 - pipeline - INFO - Created directory for story: stories\Title_Glimmering_Autumns_Enigma_In
2025-04-22 03:09:16,845 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 03:12:11,598 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-22 03:19:06,624 - pipeline - INFO - Generating story for idea: a detective with a abilty to see transparent acros...
2025-04-22 03:19:11,425 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 03:19:26,061 - pipeline - INFO - Saved content to stories\Title_Glimmering_Autumns_Enigma_In\story_bible.txt
2025-04-22 03:19:28,903 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 03:19:37,480 - pipeline - WARNING - File not found: stories\Title_Glimmering_Autumns_Enigma_In\story.txt
2025-04-22 03:20:30,788 - pipeline - INFO - Generating story for idea: a detective who can see transparent across walls...
2025-04-22 03:20:34,403 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 03:20:53,846 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-22 03:24:33,114 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-22 03:28:03,031 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-22 03:36:33,159 - pipeline - INFO - Created directory for story: stories\Title_The_Wall-Gazer_Detective_In
2025-04-22 03:36:37,688 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 03:36:46,647 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 03:36:46,684 - pipeline - INFO - Saved metadata to stories\Title_Glimmering_Autumns_Enigma_In\metadata.json
2025-04-22 03:36:46,687 - query_handler - INFO - Using chunking strategy for long prompt
2025-04-22 03:36:46,693 - query_handler - INFO - Split prompt into 2 chunks
2025-04-22 03:36:50,049 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 03:36:51,151 - pipeline - INFO - Created directory for story: stories\Title_Wall-Gazer_Whispers_In_the
2025-04-22 03:36:53,645 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 03:40:06,810 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-22 08:28:45,478 - config - INFO - Initial Model Provider: ollama
2025-04-22 08:28:45,497 - config - INFO - Initial Small Model: mistral
2025-04-22 08:28:45,502 - config - INFO - Initial Big Model: llama3
2025-04-22 08:28:45,503 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-22 08:29:59,518 - pipeline - INFO - Generating story for idea:  a detective perosn is very clever...
2025-04-22 08:30:02,147 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 08:31:31,341 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-22 08:34:23,409 - pipeline - INFO - Created directory for story: stories\Title_Bright_Minds_Mysterious_Skies
2025-04-22 08:34:25,910 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 08:37:21,632 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-22 08:45:48,522 - pipeline - INFO - Saved content to stories\Title_Bright_Minds_Mysterious_Skies\story_bible.txt
2025-04-22 08:45:51,126 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 08:55:37,851 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-22 08:59:31,113 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-04-22 08:59:31,144 - pipeline - INFO - Saved metadata to stories\Title_Bright_Minds_Mysterious_Skies\metadata.json
2025-04-22 08:59:31,148 - query_handler - INFO - Using chunking strategy for long prompt
2025-04-22 08:59:31,150 - query_handler - INFO - Split prompt into 2 chunks
2025-04-22 08:59:33,617 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 09:04:37,955 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-04-22 09:09:17,748 - query_handler - INFO - Processed chunk 1/2
2025-04-22 09:09:19,710 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 09:09:19,711 - query_handler - INFO - Cache hit for query with model mistral
2025-04-22 09:09:19,712 - query_handler - INFO - Processed chunk 2/2
2025-04-22 09:09:20,957 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-04-22 10:03:31,461 - config - INFO - Initial Model Provider: ollama
2025-04-22 10:03:31,462 - config - INFO - Initial Small Model: mistral
2025-04-22 10:03:31,463 - config - INFO - Initial Big Model: llama3
2025-04-22 10:03:31,465 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-04-22 10:03:44,730 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 10:03:44,732 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 10:03:44,734 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 10:03:57,904 - config - INFO - Configuration reloaded, using provider: openai
2025-04-22 10:03:57,904 - config - INFO - Small Model: gpt-3.5-turbo
2025-04-22 10:03:57,905 - config - INFO - Big Model: gpt-4-turbo
2025-04-22 17:52:27,468 - config - INFO - Initial Model Provider: openai
2025-04-22 17:52:27,472 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-04-22 17:52:27,472 - config - INFO - Initial Big Model: gpt-4-turbo
2025-04-22 17:52:27,473 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-09 01:49:56,068 - config - INFO - Initial Model Provider: openai
2025-06-09 01:49:56,069 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-06-09 01:49:56,069 - config - INFO - Initial Big Model: gpt-4-turbo
2025-06-09 01:49:56,069 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-15 15:46:11,276 - config - INFO - Initial Model Provider: openai
2025-06-15 15:46:11,278 - config - INFO - Initial Small Model: gpt-3.5-turbo
2025-06-15 15:46:11,279 - config - INFO - Initial Big Model: gpt-4-turbo
2025-06-15 15:46:11,279 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-15 15:54:55,556 - config - INFO - Configuration reloaded, using provider: ollama
2025-06-15 15:54:55,557 - config - INFO - Small Model: mistral
2025-06-15 15:54:55,558 - config - INFO - Big Model: llama3
2025-06-16 21:40:47,536 - config - INFO - Initial Model Provider: ollama
2025-06-16 21:40:47,537 - config - INFO - Initial Small Model: mistral
2025-06-16 21:40:47,539 - config - INFO - Initial Big Model: llama3
2025-06-16 21:40:47,540 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-17 23:23:10,573 - config - INFO - Initial Model Provider: ollama
2025-06-17 23:23:10,574 - config - INFO - Initial Small Model: mistral
2025-06-17 23:23:10,575 - config - INFO - Initial Big Model: llama3
2025-06-17 23:23:10,575 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-18 10:36:17,239 - config - INFO - Initial Model Provider: ollama
2025-06-18 10:36:17,240 - config - INFO - Initial Small Model: mistral
2025-06-18 10:36:17,241 - config - INFO - Initial Big Model: llama3
2025-06-18 10:36:17,241 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-25 15:40:48,001 - config - INFO - Initial Model Provider: ollama
2025-06-25 15:40:48,001 - config - INFO - Initial Small Model: mistral
2025-06-25 15:40:48,001 - config - INFO - Initial Big Model: llama3
2025-06-25 15:40:48,002 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-25 21:59:08,130 - config - INFO - Initial Model Provider: ollama
2025-06-25 21:59:08,131 - config - INFO - Initial Small Model: mistral
2025-06-25 21:59:08,131 - config - INFO - Initial Big Model: llama3
2025-06-25 21:59:08,132 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-25 21:59:19,773 - config - INFO - Configuration reloaded, using provider: openai
2025-06-25 21:59:19,779 - config - INFO - Small Model: gpt-3.5-turbo
2025-06-25 21:59:19,780 - config - INFO - Big Model: gpt-4-turbo
2025-06-25 21:59:35,942 - config - INFO - Configuration reloaded, using provider: ollama
2025-06-25 21:59:35,942 - config - INFO - Small Model: mistral
2025-06-25 21:59:35,942 - config - INFO - Big Model: llama3
2025-06-26 01:20:54,640 - config - INFO - Initial Model Provider: ollama
2025-06-26 01:20:54,641 - config - INFO - Initial Small Model: mistral
2025-06-26 01:20:54,641 - config - INFO - Initial Big Model: llama3
2025-06-26 01:20:54,641 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-26 01:21:25,118 - pipeline - INFO - Generating story for idea: a detective man...
2025-06-26 01:21:26,579 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 01:21:59,373 - pipeline - INFO - Generating story for idea: a detective man...
2025-06-26 01:22:06,340 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 01:22:43,656 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 01:23:30,363 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 01:27:31,126 - pipeline - INFO - Generating story for idea: a detective man...
2025-06-26 01:27:39,987 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 01:28:38,731 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 01:28:55,991 - pipeline - INFO - Created directory for story: stories\Title_Galactic_Gumshoe_Grayson_Story
2025-06-26 01:28:58,883 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 01:29:55,836 - pipeline - INFO - Created directory for story: stories\Title_Galactic_Gumshoe_Gus_In
2025-06-26 01:29:58,655 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 01:30:24,912 - pipeline - INFO - Generating story for idea: a detective man...
2025-06-26 01:30:30,228 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 01:34:01,616 - pipeline - INFO - Created directory for story: stories\Title_Galactic_Gumshoe_Mysteries_Unraveled
2025-06-26 01:34:04,415 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 01:45:01,577 - config - INFO - Initial Model Provider: ollama
2025-06-26 01:45:01,578 - config - INFO - Initial Small Model: mistral
2025-06-26 01:45:01,578 - config - INFO - Initial Big Model: llama3
2025-06-26 01:45:01,579 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-26 01:47:07,976 - pipeline - INFO - Generating story for idea: a detective man
...
2025-06-26 01:47:09,220 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 01:48:41,266 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 01:49:02,139 - query_handler - ERROR - Error generating response with mistral: an error was encountered while running the model: read tcp 127.0.0.1:52000->127.0.0.1:51998: wsarecv: An existing connection was forcibly closed by the remote host. (status code: -1)
2025-06-26 01:49:02,301 - pipeline - INFO - Created directory for story: stories\Error_an_error_was_encountered
2025-06-26 01:49:05,702 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 01:57:40,457 - config - INFO - Initial Model Provider: ollama
2025-06-26 01:57:40,458 - config - INFO - Initial Small Model: mistral
2025-06-26 01:57:40,459 - config - INFO - Initial Big Model: llama3
2025-06-26 01:57:40,459 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-26 01:58:03,690 - pipeline - INFO - Generating story for idea: wife killed a man...
2025-06-26 01:58:06,211 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 01:59:21,316 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 02:03:13,442 - pipeline - INFO - Created directory for story: stories\Title_Mystery_of_the_Midnight
2025-06-26 02:03:15,059 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 02:07:39,873 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 02:15:48,875 - pipeline - INFO - Saved content to stories\Title_Mystery_of_the_Midnight\story_bible.txt
2025-06-26 02:15:50,732 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 02:21:52,512 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 02:29:51,112 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-06-26 02:29:51,183 - pipeline - INFO - Saved metadata to stories\Title_Mystery_of_the_Midnight\metadata.json
2025-06-26 02:29:51,186 - query_handler - INFO - Using chunking strategy for long prompt
2025-06-26 02:29:51,188 - query_handler - INFO - Split prompt into 2 chunks
2025-06-26 02:29:53,467 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 02:33:50,167 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 09:19:20,270 - query_handler - INFO - Processed chunk 1/2
2025-06-26 09:19:22,703 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 09:19:22,708 - query_handler - INFO - Cache hit for query with model mistral
2025-06-26 09:19:22,709 - query_handler - INFO - Processed chunk 2/2
2025-06-26 09:19:25,498 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 09:26:17,492 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 09:35:03,196 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 11:00:48,770 - pipeline - WARNING - File not found: stories\Title_Galactic_Gumshoe_Gus_In\story.txt
2025-06-26 11:05:50,663 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 11:10:49,881 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-06-26 11:10:53,449 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 11:17:02,274 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 11:21:52,245 - pipeline - INFO - Saved metadata to stories\Title_Mystery_of_the_Midnight\metadata.json
2025-06-26 11:21:52,331 - query_handler - INFO - Using chunking strategy for long prompt
2025-06-26 11:21:52,343 - query_handler - INFO - Split prompt into 3 chunks
2025-06-26 11:21:55,395 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 11:26:18,416 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 11:34:41,728 - query_handler - INFO - Processed chunk 1/3
2025-06-26 11:34:45,657 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 11:34:45,660 - query_handler - INFO - Cache hit for query with model mistral
2025-06-26 11:34:45,661 - query_handler - INFO - Processed chunk 2/3
2025-06-26 11:34:48,440 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 11:34:48,441 - query_handler - INFO - Cache hit for query with model mistral
2025-06-26 11:34:48,442 - query_handler - INFO - Processed chunk 3/3
2025-06-26 11:34:51,166 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 11:47:03,997 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 11:53:12,902 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 11:57:53,171 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 12:02:21,122 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 12:06:38,897 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 12:10:21,352 - pipeline - INFO - Saved metadata to stories\Title_Mystery_of_the_Midnight\metadata.json
2025-06-26 12:10:21,396 - pipeline - INFO - Saved content to stories\Title_Mystery_of_the_Midnight\story.txt
2025-06-26 12:10:21,404 - pipeline - INFO - Saved content to stories\Title_Mystery_of_the_Midnight\story_summaries.txt
2025-06-26 12:10:21,408 - pipeline - INFO - Story 'Title_Mystery_of_the_Midnight' generated successfully with 2 episodes
2025-06-26 12:41:32,213 - config - INFO - Initial Model Provider: ollama
2025-06-26 12:41:32,214 - config - INFO - Initial Small Model: mistral:7b-text-q4_0
2025-06-26 12:41:32,214 - config - INFO - Initial Big Model: mistral:7b-text-q4_0
2025-06-26 12:41:32,215 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-26 12:41:35,284 - config - INFO - Configuration reloaded, using provider: ollama
2025-06-26 12:41:35,284 - config - INFO - Small Model: mistral
2025-06-26 12:41:35,284 - config - INFO - Big Model: llama3
2025-06-26 12:41:53,148 - pipeline - INFO - Generating story for idea: shakespeare...
2025-06-26 12:41:54,263 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 12:43:29,417 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 12:49:02,518 - pipeline - INFO - Created directory for story: stories\Title_Bards_Echo_In_the
2025-06-26 12:49:06,524 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 12:53:25,606 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 13:13:25,202 - config - INFO - Initial Model Provider: ollama
2025-06-26 13:13:25,203 - config - INFO - Initial Small Model: mistral
2025-06-26 13:13:25,203 - config - INFO - Initial Big Model: llama3
2025-06-26 13:13:25,204 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-26 13:13:29,907 - config - INFO - Configuration reloaded, using provider: ollama
2025-06-26 13:13:29,908 - config - INFO - Small Model: mistral:7b-text-q4_0
2025-06-26 13:13:29,908 - config - INFO - Big Model: mistral:7b-text-q4_0
2025-06-26 13:32:08,667 - config - INFO - Initial Model Provider: ollama
2025-06-26 13:32:08,668 - config - INFO - Initial Small Model: mistral:7b-text-q4_0
2025-06-26 13:32:08,668 - config - INFO - Initial Big Model: mistral:7b-text-q4_0
2025-06-26 13:32:08,669 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-26 13:32:08,807 - config - INFO - Configuration reloaded, using provider: ollama
2025-06-26 13:32:08,808 - config - INFO - Small Model: mistral
2025-06-26 13:32:08,809 - config - INFO - Big Model: llama3
2025-06-26 13:46:35,254 - config - INFO - Initial Model Provider: ollama
2025-06-26 13:46:35,255 - config - INFO - Initial Small Model: mistral
2025-06-26 13:46:35,255 - config - INFO - Initial Big Model: llama3
2025-06-26 13:46:35,255 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-26 13:46:45,639 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 13:48:52,127 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 13:52:56,656 - pipeline - INFO - Generating story for idea: on a barren island...
2025-06-26 13:53:03,639 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 13:53:36,207 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 13:53:40,839 - query_handler - INFO - Querying with memory context
2025-06-26 13:53:42,843 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 13:56:39,900 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 14:04:35,208 - pipeline - INFO - Created directory for story: stories\Title_Island_of_Whispers_In
2025-06-26 14:04:37,917 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 14:05:16,089 - query_handler - INFO - Using chunking strategy for long prompt
2025-06-26 14:05:16,098 - query_handler - INFO - Split prompt into 2 chunks
2025-06-26 14:05:18,540 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 14:10:00,433 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 14:16:08,012 - pipeline - INFO - Saved content to stories\Title_Island_of_Whispers_In\story_bible.txt
2025-06-26 14:16:10,255 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 14:18:57,419 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 14:23:56,271 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 14:24:00,599 - pipeline - WARNING - File not found: stories\Title_Island_of_Whispers_In\story.txt
2025-06-26 14:31:02,041 - pipeline - INFO - Saved metadata to stories\Title_Island_of_Whispers_In\metadata.json
2025-06-26 14:31:02,208 - query_handler - INFO - Using chunking strategy for long prompt
2025-06-26 14:31:02,234 - query_handler - INFO - Split prompt into 2 chunks
2025-06-26 14:31:09,634 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 14:35:04,101 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 14:36:50,806 - query_handler - INFO - Processed chunk 1/2
2025-06-26 14:36:54,124 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 14:36:54,126 - query_handler - INFO - Cache hit for query with model mistral
2025-06-26 14:36:54,127 - query_handler - INFO - Processed chunk 2/2
2025-06-26 14:36:57,553 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 14:47:17,954 - pipeline - INFO - Generating story for idea: a woman met with a man...
2025-06-26 14:47:23,826 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 14:47:44,770 - query_handler - INFO - Processed chunk 1/2
2025-06-26 14:47:47,115 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 14:47:47,116 - query_handler - INFO - Cache hit for query with model mistral
2025-06-26 14:47:47,116 - query_handler - INFO - Processed chunk 2/2
2025-06-26 14:47:48,892 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 14:52:08,846 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 15:00:32,289 - pipeline - INFO - Saved content to stories\Chronicles_of_Timeless_Love\story.txt
2025-06-26 15:00:36,732 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 15:05:11,163 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 15:15:02,435 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 16:21:12,647 - config - INFO - Initial Model Provider: ollama
2025-06-26 16:21:12,647 - config - INFO - Initial Small Model: mistral:7b-text-q4_0
2025-06-26 16:21:12,647 - config - INFO - Initial Big Model: mistral:7b-text-q4_0
2025-06-26 16:21:12,648 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-06-26 16:21:16,301 - config - INFO - Configuration reloaded, using provider: ollama
2025-06-26 16:21:16,301 - config - INFO - Small Model: mistral
2025-06-26 16:21:16,301 - config - INFO - Big Model: llama3
2025-06-26 16:21:48,789 - pipeline - INFO - Generating story for idea: iron man created a new suit mark up - 85 armor ...
2025-06-26 16:21:49,936 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 16:22:58,861 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 16:29:21,943 - pipeline - INFO - Created directory for story: stories\Title_Ironhearts_85th_Quest_The
2025-06-26 16:29:24,111 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 16:33:56,591 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 16:40:07,750 - pipeline - INFO - Saved content to stories\Title_Ironhearts_85th_Quest_The\story_bible.txt
2025-06-26 16:40:09,879 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 16:45:06,711 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 16:49:00,477 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-06-26 16:49:00,519 - pipeline - INFO - Saved metadata to stories\Title_Ironhearts_85th_Quest_The\metadata.json
2025-06-26 16:49:00,523 - query_handler - INFO - Using chunking strategy for long prompt
2025-06-26 16:49:00,528 - query_handler - INFO - Split prompt into 3 chunks
2025-06-26 16:49:02,482 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 16:51:11,635 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 16:56:15,080 - query_handler - INFO - Processed chunk 1/3
2025-06-26 16:56:16,580 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 16:56:16,582 - query_handler - INFO - Cache hit for query with model mistral
2025-06-26 16:56:16,583 - query_handler - INFO - Processed chunk 2/3
2025-06-26 16:56:17,747 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 16:56:17,748 - query_handler - INFO - Cache hit for query with model mistral
2025-06-26 16:56:17,751 - query_handler - INFO - Processed chunk 3/3
2025-06-26 16:56:18,974 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 17:03:23,783 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 17:07:48,840 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 17:10:45,893 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 17:13:33,970 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 17:17:02,361 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 17:19:32,159 - pipeline - INFO - Saved metadata to stories\Title_Ironhearts_85th_Quest_The\metadata.json
2025-06-26 17:19:32,161 - query_handler - INFO - Using chunking strategy for long prompt
2025-06-26 17:19:32,162 - query_handler - INFO - Split prompt into 4 chunks
2025-06-26 17:19:33,908 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 17:21:51,510 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 17:27:12,265 - query_handler - INFO - Processed chunk 1/4
2025-06-26 17:27:14,504 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 17:27:14,506 - query_handler - INFO - Cache hit for query with model mistral
2025-06-26 17:27:14,507 - query_handler - INFO - Processed chunk 2/4
2025-06-26 17:27:17,420 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 17:27:17,420 - query_handler - INFO - Cache hit for query with model mistral
2025-06-26 17:27:17,421 - query_handler - INFO - Processed chunk 3/4
2025-06-26 17:27:19,943 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 17:27:19,943 - query_handler - INFO - Cache hit for query with model mistral
2025-06-26 17:27:19,944 - query_handler - INFO - Processed chunk 4/4
2025-06-26 17:27:23,997 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 17:35:28,079 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 17:40:15,356 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 17:44:16,454 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 17:46:28,443 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-06-26 17:46:30,394 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-06-26 17:50:39,810 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-06-26 17:54:20,962 - pipeline - INFO - Saved metadata to stories\Title_Ironhearts_85th_Quest_The\metadata.json
2025-06-26 17:54:20,978 - pipeline - INFO - Saved content to stories\Title_Ironhearts_85th_Quest_The\story.txt
2025-06-26 17:54:20,983 - pipeline - INFO - Saved content to stories\Title_Ironhearts_85th_Quest_The\story_summaries.txt
2025-06-26 17:54:20,985 - pipeline - INFO - Story 'Title_Ironhearts_85th_Quest_The' generated successfully with 2 episodes
2025-07-02 18:24:03,762 - config - INFO - Initial Model Provider: ollama
2025-07-02 18:24:03,763 - config - INFO - Initial Small Model: mistral
2025-07-02 18:24:03,763 - config - INFO - Initial Big Model: llama3
2025-07-02 18:24:03,763 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-07-02 18:24:57,454 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:25:01,548 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-02 18:25:01,550 - query_handler - INFO - Querying with memory context
2025-07-02 18:25:02,855 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:25:06,907 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-02 18:25:08,156 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:25:12,229 - query_handler - ERROR - Error generating response with llama3: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-02 18:25:12,252 - pipeline - INFO - Saved content to stories\Chronicles_of_Timeless_Love\story.txt
2025-07-02 18:25:13,315 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:25:17,360 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-02 18:25:17,361 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-07-02 18:25:18,388 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:25:22,448 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-02 18:25:22,450 - pipeline - INFO - Saved content to stories\Chronicles_of_Timeless_Love\story_summaries.txt
2025-07-02 18:25:22,452 - pipeline - INFO - Saved metadata to stories\Chronicles_of_Timeless_Love\metadata.json
2025-07-02 18:25:22,453 - pipeline - INFO - New episode 2 added to 'Chronicles_of_Timeless_Love'
2025-07-02 18:25:55,107 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:25:59,164 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-02 18:25:59,164 - query_handler - INFO - Querying with memory context
2025-07-02 18:26:00,267 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:26:04,353 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-02 18:26:05,317 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:26:09,380 - query_handler - ERROR - Error generating response with llama3: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-02 18:26:09,384 - pipeline - INFO - Saved content to stories\Chronicles_of_Timeless_Love\story.txt
2025-07-02 18:26:10,525 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:26:14,575 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-02 18:26:14,576 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-07-02 18:26:15,782 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:26:19,830 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-02 18:26:19,831 - pipeline - INFO - Saved content to stories\Chronicles_of_Timeless_Love\story_summaries.txt
2025-07-02 18:26:19,833 - pipeline - INFO - Saved metadata to stories\Chronicles_of_Timeless_Love\metadata.json
2025-07-02 18:26:19,834 - pipeline - INFO - New episode 3 added to 'Chronicles_of_Timeless_Love'
2025-07-02 18:34:39,507 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:36:38,665 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:38:17,340 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-02 18:41:18,732 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-02 18:50:11,583 - query_handler - INFO - Querying with memory context
2025-07-02 18:50:13,329 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:50:17,305 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 18:53:35,860 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-02 18:58:31,870 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-02 19:02:45,740 - query_handler - INFO - Querying with memory context
2025-07-02 19:02:50,263 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 19:12:12,554 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-02 19:26:50,509 - query_handler - INFO - Using chunking strategy for long prompt
2025-07-02 19:26:50,566 - query_handler - INFO - Split prompt into 2 chunks
2025-07-02 19:26:55,721 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 19:31:28,154 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-02 19:34:26,657 - query_handler - INFO - Querying with memory context
2025-07-02 19:34:30,353 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-02 19:43:59,295 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-02 19:46:36,836 - query_handler - INFO - Using chunking strategy for long prompt
2025-07-02 19:46:36,873 - query_handler - INFO - Split prompt into 2 chunks
2025-07-02 19:46:40,541 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-03 23:25:54,904 - config - INFO - Initial Model Provider: ollama
2025-07-03 23:25:54,905 - config - INFO - Initial Small Model: mistral
2025-07-03 23:25:54,906 - config - INFO - Initial Big Model: llama3
2025-07-03 23:25:54,906 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-07-03 23:26:33,092 - pipeline - INFO - Generating story for idea: a good man ...
2025-07-03 23:26:35,912 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-03 23:26:40,018 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-03 23:26:40,022 - pipeline - INFO - Created directory for story: stories\Error_WinError_10061_No_connection
2025-07-03 23:26:44,189 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-03 23:26:48,234 - query_handler - ERROR - Error generating response with llama3: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-03 23:26:48,240 - pipeline - INFO - Saved content to stories\Error_WinError_10061_No_connection\story_bible.txt
2025-07-03 23:26:49,416 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-03 23:26:53,470 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-03 23:26:53,472 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-07-03 23:26:53,476 - pipeline - INFO - Saved metadata to stories\Error_WinError_10061_No_connection\metadata.json
2025-07-03 23:26:54,893 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-03 23:26:58,944 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-03 23:27:00,096 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-03 23:27:04,134 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-03 23:27:04,135 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-07-03 23:27:05,476 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-03 23:27:09,533 - query_handler - ERROR - Error generating response with mistral: [WinError 10061] No connection could be made because the target machine actively refused it
2025-07-03 23:27:09,538 - pipeline - INFO - Saved metadata to stories\Error_WinError_10061_No_connection\metadata.json
2025-07-03 23:27:09,545 - pipeline - INFO - Saved content to stories\Error_WinError_10061_No_connection\story.txt
2025-07-03 23:27:09,552 - pipeline - INFO - Saved content to stories\Error_WinError_10061_No_connection\story_summaries.txt
2025-07-03 23:27:09,554 - pipeline - INFO - Story 'Error_WinError_10061_No_connection' generated successfully with 1 episodes
2025-07-03 23:32:38,829 - config - INFO - Initial Model Provider: ollama
2025-07-03 23:32:38,831 - config - INFO - Initial Small Model: mistral
2025-07-03 23:32:38,831 - config - INFO - Initial Big Model: llama3
2025-07-03 23:32:38,831 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-07-03 23:48:32,889 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-03 23:48:32,890 - config - INFO - Small Model: gemma
2025-07-03 23:48:32,890 - config - INFO - Big Model: llama3
2025-07-03 23:49:10,662 - pipeline - INFO - Generating story for idea: a good day ...
2025-07-03 23:49:13,495 - query_handler - INFO - Initialized Ollama models: small=gemma, big=llama3
2025-07-03 23:49:15,604 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 404 Not Found"
2025-07-03 23:49:15,606 - query_handler - ERROR - Error generating response with gemma: model 'gemma' not found (status code: 404)
2025-07-03 23:49:15,628 - pipeline - INFO - Created directory for story: stories\Error_model_gemma_not_found
2025-07-03 23:49:19,228 - query_handler - INFO - Initialized Ollama models: small=gemma, big=llama3
2025-07-03 23:51:46,205 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-03 23:55:27,939 - config - INFO - Initial Model Provider: ollama
2025-07-03 23:55:27,940 - config - INFO - Initial Small Model: gemma
2025-07-03 23:55:27,941 - config - INFO - Initial Big Model: llama3
2025-07-03 23:55:27,941 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-07-03 23:55:33,400 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-03 23:55:33,401 - config - INFO - Small Model: mistral
2025-07-03 23:55:33,401 - config - INFO - Big Model: llama3
2025-07-03 23:58:08,638 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-03 23:58:08,639 - config - INFO - Small Model: gemma
2025-07-03 23:58:08,639 - config - INFO - Big Model: llama3
2025-07-04 00:00:23,314 - pipeline - INFO - Generating story for idea: a good guy...
2025-07-04 00:00:24,676 - query_handler - INFO - Initialized Ollama models: small=gemma, big=llama3
2025-07-04 00:00:26,876 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 404 Not Found"
2025-07-04 00:00:26,878 - query_handler - ERROR - Error generating response with gemma: model 'gemma' not found (status code: 404)
2025-07-04 00:00:26,892 - pipeline - INFO - Created directory for story: stories\Error_model_gemma_not_found
2025-07-04 00:00:29,339 - query_handler - INFO - Initialized Ollama models: small=gemma, big=llama3
2025-07-04 00:02:43,888 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-04 00:10:18,719 - config - INFO - Initial Model Provider: ollama
2025-07-04 00:10:18,720 - config - INFO - Initial Small Model: gemma:2b
2025-07-04 00:10:18,720 - config - INFO - Initial Big Model: llama3
2025-07-04 00:10:18,720 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-07-04 00:10:22,071 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 00:10:22,072 - config - INFO - Small Model: mistral
2025-07-04 00:10:22,072 - config - INFO - Big Model: llama3
2025-07-04 00:10:22,636 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 00:10:22,636 - config - INFO - Small Model: gemma
2025-07-04 00:10:22,637 - config - INFO - Big Model: llama3
2025-07-04 00:10:57,908 - pipeline - INFO - Generating story for idea: a good guy...
2025-07-04 00:11:00,451 - query_handler - INFO - Initialized Ollama models: small=gemma, big=llama3
2025-07-04 00:11:02,672 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 404 Not Found"
2025-07-04 00:11:02,674 - query_handler - ERROR - Error generating response with gemma: model 'gemma' not found (status code: 404)
2025-07-04 00:11:02,685 - pipeline - INFO - Created directory for story: stories\Error_model_gemma_not_found
2025-07-04 00:11:04,779 - query_handler - INFO - Initialized Ollama models: small=gemma, big=llama3
2025-07-04 00:11:29,058 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-04 00:15:36,269 - config - INFO - Initial Model Provider: ollama
2025-07-04 00:15:36,270 - config - INFO - Initial Small Model: gemma
2025-07-04 00:15:36,270 - config - INFO - Initial Big Model: llama3
2025-07-04 00:15:36,270 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-07-04 00:15:42,066 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 00:15:42,067 - config - INFO - Small Model: mistral
2025-07-04 00:15:42,068 - config - INFO - Big Model: llama3
2025-07-04 00:16:17,518 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 00:16:17,519 - config - INFO - Small Model: gemma
2025-07-04 00:16:17,520 - config - INFO - Big Model: llama3
2025-07-04 00:16:58,554 - pipeline - INFO - Generating story for idea: a good boy...
2025-07-04 00:17:01,108 - query_handler - INFO - Initialized Ollama models: small=gemma, big=llama3
2025-07-04 00:17:03,434 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 404 Not Found"
2025-07-04 00:17:03,437 - query_handler - ERROR - Error generating response with gemma: model 'gemma' not found (status code: 404)
2025-07-04 00:17:03,447 - pipeline - INFO - Created directory for story: stories\Error_model_gemma_not_found
2025-07-04 00:17:06,456 - query_handler - INFO - Initialized Ollama models: small=gemma, big=llama3
2025-07-04 00:19:03,072 - config - INFO - Initial Model Provider: ollama
2025-07-04 00:19:03,073 - config - INFO - Initial Small Model: gemma
2025-07-04 00:19:03,074 - config - INFO - Initial Big Model: llama3
2025-07-04 00:19:03,074 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-07-04 00:19:07,222 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 00:19:07,226 - config - INFO - Small Model: mistral
2025-07-04 00:19:07,230 - config - INFO - Big Model: llama3
2025-07-04 00:26:20,652 - config - INFO - Initial Model Provider: ollama
2025-07-04 00:26:20,653 - config - INFO - Initial Small Model: gemma:2b
2025-07-04 00:26:20,653 - config - INFO - Initial Big Model: llama3
2025-07-04 00:26:20,653 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-07-04 00:26:23,596 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 00:26:23,596 - config - INFO - Small Model: mistral
2025-07-04 00:26:23,596 - config - INFO - Big Model: llama3
2025-07-04 00:27:16,615 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 00:27:16,616 - config - INFO - Small Model: gemma
2025-07-04 00:27:16,616 - config - INFO - Big Model: llama3
2025-07-04 00:33:05,902 - config - INFO - Initial Model Provider: ollama
2025-07-04 00:33:05,902 - config - INFO - Initial Small Model: gemma:2b
2025-07-04 00:33:05,902 - config - INFO - Initial Big Model: llama3
2025-07-04 00:33:05,903 - config - INFO - Memory Settings: Max Episodes=3, Summarization=True
2025-07-04 00:33:07,778 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 00:33:07,778 - config - INFO - Small Model: mistral
2025-07-04 00:33:07,779 - config - INFO - Big Model: llama3
2025-07-04 01:06:58,084 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 01:06:58,085 - config - INFO - Small Model: phi
2025-07-04 01:06:58,085 - config - INFO - Big Model: llama3
2025-07-04 01:07:04,359 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 01:07:04,359 - config - INFO - Small Model: mistral
2025-07-04 01:07:04,360 - config - INFO - Big Model: llama3
2025-07-04 01:07:13,253 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 01:07:13,254 - config - INFO - Small Model: phi
2025-07-04 01:07:13,254 - config - INFO - Big Model: llama3
2025-07-04 01:08:13,858 - pipeline - INFO - Generating story for idea: a good children ...
2025-07-04 01:08:15,135 - query_handler - INFO - Initialized Ollama models: small=phi, big=llama3
2025-07-04 01:08:42,315 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-04 01:09:11,001 - pipeline - INFO - Created directory for story: stories\A_possible_story_for_this
2025-07-04 01:09:12,381 - query_handler - INFO - Initialized Ollama models: small=phi, big=llama3
2025-07-04 01:11:16,868 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-04 01:20:23,196 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 01:20:23,252 - config - INFO - Small Model: mistral
2025-07-04 01:20:23,254 - config - INFO - Big Model: llama3
2025-07-04 01:20:56,832 - pipeline - INFO - Saved content to stories\A_possible_story_for_this\story_bible.txt
2025-07-04 01:20:58,737 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-04 01:27:24,089 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-04 01:32:07,481 - pipeline - WARNING - JSON parsing failed for character extraction from story bible
2025-07-04 01:32:07,521 - pipeline - INFO - Saved metadata to stories\A_possible_story_for_this\metadata.json
2025-07-04 01:32:10,375 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-04 01:35:00,216 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-04 01:39:12,911 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-04 01:46:45,487 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 01:46:45,540 - config - INFO - Small Model: phi
2025-07-04 01:46:45,545 - config - INFO - Big Model: llama3
2025-07-04 01:47:26,255 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-04 01:47:45,911 - config - INFO - Configuration reloaded, using provider: ollama
2025-07-04 01:47:45,917 - config - INFO - Small Model: mistral
2025-07-04 01:47:45,920 - config - INFO - Big Model: llama3
2025-07-04 01:51:19,910 - pipeline - WARNING - JSON parsing failed for character extraction, using regex fallback
2025-07-04 01:51:22,261 - query_handler - INFO - Initialized Ollama models: small=mistral, big=llama3
2025-07-04 01:54:16,663 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/generate "HTTP/1.1 200 OK"
2025-07-04 01:59:47,039 - pipeline - INFO - Saved metadata to stories\A_possible_story_for_this\metadata.json
2025-07-04 01:59:47,072 - pipeline - INFO - Saved content to stories\A_possible_story_for_this\story.txt
2025-07-04 01:59:47,077 - pipeline - INFO - Saved content to stories\A_possible_story_for_this\story_summaries.txt
2025-07-04 01:59:47,078 - pipeline - INFO - Story 'A_possible_story_for_this' generated successfully with 1 episodes
